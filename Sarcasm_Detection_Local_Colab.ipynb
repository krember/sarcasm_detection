{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Sarcasm Detection Local Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krember/sarcasm_detection/blob/master/Sarcasm_Detection_Local_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXycJlnqk7cu",
        "colab_type": "text"
      },
      "source": [
        "# Intro to Sarcasm Detection Problem\n",
        "\n",
        "We have decided to work on Sarcase Detection project as that was really interesting for us and also it was worthy to figure out how the NN will be able to distinguish the sarcasm from the text while even some human being are not able to.\n",
        "Also in our everyday life we usually see big and attractive news headlines (sometimes fiables,sometimes not at all).\n",
        "Could you really know which one is real and which one is fake ?(My granny and sometimes even mom cannot! :D )\n",
        "\n",
        "We found the dataset from Kaggle and it is the collection of news headlines from TheOnion and HuffPost.\n",
        "Both of these newspapers are collecting the information about current events.\n",
        "TheOnion headlines both in brief and in photos categories are all sarcasric context while at the same time the HuffPost has only non sarcastic headlines.\n",
        "\n",
        "In our dataset we have both of them (sarcastic and non-sarcastic).\n",
        "The advantages of these data sets are\n",
        "\n",
        "1. Since news headlines are written by professionals in a formal manner, there are no spelling mistakes and informal usage. This reduces the sparsity and also increases the chance of finding pre-trained embeddings.\n",
        "2. Furthermore, since the sole purpose of TheOnion is to publish sarcastic news, we get high-quality labels with much less noise as compared to Twitter datasets.\n",
        "3. Unlike tweets which are replies to other tweets, the news headlines we obtained are self-contained. This would help us in teasing apart the real sarcastic elements.\n",
        "4. Dataset is nor noisy neither imbalanced (based on what google ml developers claim https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data )\n",
        "\n",
        "As you could already see our benchmark is the tweeter sarcasm detection analysis and other social media sarcasm detections based on imbalanced classificaion (in our case the data used was not balanced neither).\n",
        "\n",
        "Here is the article we used to look up on https://www.researchgate.net/publication/278658179_Sarcasm_Detection_in_Social_Media_Based_on_Imbalanced_Classification.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dhVVn_ZjjPx",
        "colab_type": "text"
      },
      "source": [
        "Before starting the coding part of the work one should always have the imported the libraries needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ca4oUGXGaUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import spacy\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torch import nn, optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwFWStIGGaUf",
        "colab_type": "text"
      },
      "source": [
        "The dataset is imported from the github and it is stored in JSON format.\n",
        "You can also see that below there are the links to the articles,their headlines and also the information about being sarcastic (0-not sarcastic,1 sarcasric)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jD0TyCXXd21",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0dc19ab3-9f8e-4bca-ba0f-2929eddc5cf9"
      },
      "source": [
        "#Let's start from providing Colab access to Google Drive to be able load the file with the data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvQTPs89GaUl",
        "colab_type": "code",
        "outputId": "f8bddd92-268b-4ea2-8b8e-9d6fc82ca973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data_GH_path = 'https://raw.githubusercontent.com/krember/sarcasm_detection/master/Sarcasm_Headlines_Dataset.json'\n",
        "\n",
        "df = pd.read_json(data_GH_path, lines = True)\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_link</th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        article_link  ... is_sarcastic\n",
              "0  https://www.huffingtonpost.com/entry/versace-b...  ...            0\n",
              "1  https://www.huffingtonpost.com/entry/roseanne-...  ...            0\n",
              "2  https://local.theonion.com/mom-starting-to-fea...  ...            1\n",
              "3  https://politics.theonion.com/boehner-just-wan...  ...            1\n",
              "4  https://www.huffingtonpost.com/entry/jk-rowlin...  ...            0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW0SLLnQ6vLb",
        "colab_type": "code",
        "outputId": "6195c6cb-d479-4522-c6ff-e8f363a7e796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = df[['headline','is_sarcastic']]\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  is_sarcastic\n",
              "0  former versace store clerk sues over secret 'b...             0\n",
              "1  the 'roseanne' revival catches up to our thorn...             0\n",
              "2  mom starting to fear son's web series closest ...             1\n",
              "3  boehner just wants wife to listen, not come up...             1\n",
              "4  j.k. rowling wishes snape happy birthday in th...             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZuqyNVT6yL8",
        "colab_type": "code",
        "outputId": "cbac7db5-0eef-4c5c-c6fe-866cc49cb1c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "# Check for normalization\n",
        "sns.countplot(df.is_sarcastic)\n",
        "plt.xlabel('Label')\n",
        "plt.title('Sarcasm vs Non-sarcasm')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Sarcasm vs Non-sarcasm')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riCPbSSxGaU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform dataset to have only headline and sarcastic label\n",
        "# Also split headline text into words\n",
        "HEADLINE = data.Field(tokenize='spacy', include_lengths = True)\n",
        "ISSARCASTIC = data.LabelField()\n",
        "\n",
        "sarcasm_data = data.TabularDataset(\n",
        "    path = '/content/drive/My Drive/Deep Learning - AUA/Sarcasm Detection/Sarcasm_Headlines_Dataset.json',\n",
        "    format='json',\n",
        "    fields={\n",
        "        'headline':('headline', HEADLINE),\n",
        "        'is_sarcastic':('sarcastic', ISSARCASTIC)\n",
        "    }\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "290DckQJGaVE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dcdf4e30-6527-4565-9795-2e1f0fd8e421"
      },
      "source": [
        "print(vars(sarcasm_data[0]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'headline': ['former', 'versace', 'store', 'clerk', 'sues', 'over', 'secret', \"'\", 'black', 'code', \"'\", 'for', 'minority', 'shoppers'], 'sarcastic': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q5f0ke3zTgsR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "4c3a1d0d-539e-4080-af35-11eb57b14b55"
      },
      "source": [
        "# Not a good idea to analyse words individually\n",
        "# However, it is obvious that Trump is the largest source of sarcastic headlines )))\n",
        "from collections import Counter\n",
        "c = Counter(\" \".join(df[\"headline\"]).split()).most_common(20)\n",
        "c\n",
        "# Thinking of TF-IDF for future"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('to', 8206),\n",
              " ('of', 5593),\n",
              " ('the', 5177),\n",
              " ('in', 4170),\n",
              " ('for', 3297),\n",
              " ('a', 2961),\n",
              " ('on', 2371),\n",
              " ('and', 1885),\n",
              " ('with', 1797),\n",
              " ('is', 1666),\n",
              " ('new', 1485),\n",
              " ('man', 1229),\n",
              " ('from', 1221),\n",
              " ('at', 1189),\n",
              " ('trump', 1157),\n",
              " ('about', 1051),\n",
              " ('you', 914),\n",
              " ('by', 885),\n",
              " ('this', 882),\n",
              " ('after', 838)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9NQJZm98TeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split to train and test\n",
        "train_data, test_data = sarcasm_data.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoALm8RW9jEW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d977bcf0-993e-4e88-a330-dc38861c97b2"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8013"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwMlHch59osd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "78100a73-2018-42b9-fed3-c052e444b94b"
      },
      "source": [
        "# Bulding vocabulary from each sequence of training data\n",
        "HEADLINE.build_vocab(train_data, \n",
        "                 max_size = 50_000, \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "ISSARCASTIC.build_vocab(train_data)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:29, 2.21MB/s]                           \n",
            "100%|█████████▉| 399114/400000 [00:24<00:00, 16721.38it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIDXYrSr9o9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, test_data), \n",
        "    batch_size = 64,\n",
        "    sort_key = lambda x:len(x.headline),\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYrNkOCF9o7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# recurrent neural network (RNN)\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        super(RNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional,\n",
        "                          dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self, text, text_lengths):\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        return self.fc(hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5FyJlCL9o5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define RNN model ( hyperparameters )\n",
        "EMBEDDING_DIM = 100\n",
        "PAD_IDX = HEADLINE.vocab.stoi[HEADLINE.pad_token]\n",
        "\n",
        "model = RNN(vocab_size = len(HEADLINE.vocab), embedding_dim = EMBEDDING_DIM, hidden_dim = 256,\n",
        "            output_dim = 1, n_layers = 2, bidirectional = True, dropout = 0.5, pad_idx = PAD_IDX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66PdLGLP9o1d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef7a88d4-50e9-41e4-c68e-bd093584dd3c"
      },
      "source": [
        "# Print model parameters summary\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 4,504,657 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ5HDijY9oxm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "282aa76f-c403-4d63-9e81-96ace0e1f0f3"
      },
      "source": [
        "# Dense vector representation for words\n",
        "pretrained_embeddings = HEADLINE.vocab.vectors\n",
        "\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "UNK_IDX = HEADLINE.vocab.stoi[HEADLINE.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [-1.8970e-01,  5.0024e-02,  1.9084e-01,  ..., -3.9804e-01,\n",
            "          4.7647e-01, -1.5983e-01],\n",
            "        ...,\n",
            "        [ 3.4814e-01,  2.5838e-01, -8.8865e-01,  ...,  2.7634e-02,\n",
            "         -9.2952e-01,  8.2323e-02],\n",
            "        [ 1.1097e-01,  3.6155e-01,  2.0370e-01,  ...,  2.2696e-01,\n",
            "          3.0238e-01, -5.6025e-04],\n",
            "        [ 7.6493e-01,  1.3564e-02,  4.6148e-01,  ...,  1.6122e-01,\n",
            "          5.5549e-01, -3.4158e-01]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auZp_KT9-Mqu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd627c75-d3ec-4ff9-ca9b-89a9b13c5fda"
      },
      "source": [
        "# Learning rate optimization\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r100%|█████████▉| 399114/400000 [00:40<00:00, 16721.38it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTcU6ACe-MtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    return correct.sum() / len(correct)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwJ54WLJ-hYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0.0\n",
        "    epoch_acc = 0.0\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        text, text_lengths = batch.headline\n",
        "        \n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "#         print(predictions)\n",
        "        loss = criterion(predictions, batch.sarcastic.type_as(predictions))\n",
        "        acc = binary_accuracy(predictions, batch.sarcastic.type_as(predictions))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgPj0lSp-hd6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "78e22bf2-3b69-4fda-912b-db1145846d8b"
      },
      "source": [
        "# Training the model\n",
        "N_EPOCHS = 15\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # Calculated training time of this epoch\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    epoch_mins = int(elapsed_time / 60)\n",
        "    epoch_secs = int(elapsed_time - (epoch_mins * 60))\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.500 | Train Acc: 75.38%\n",
            "Epoch: 02 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.360 | Train Acc: 84.10%\n",
            "Epoch: 03 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.297 | Train Acc: 87.58%\n",
            "Epoch: 04 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.245 | Train Acc: 89.80%\n",
            "Epoch: 05 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.208 | Train Acc: 91.77%\n",
            "Epoch: 06 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.174 | Train Acc: 93.22%\n",
            "Epoch: 07 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.146 | Train Acc: 94.35%\n",
            "Epoch: 08 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.126 | Train Acc: 95.02%\n",
            "Epoch: 09 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.106 | Train Acc: 95.99%\n",
            "Epoch: 10 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.099 | Train Acc: 96.22%\n",
            "Epoch: 11 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.081 | Train Acc: 96.90%\n",
            "Epoch: 12 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.069 | Train Acc: 97.51%\n",
            "Epoch: 13 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.063 | Train Acc: 97.61%\n",
            "Epoch: 14 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.053 | Train Acc: 98.02%\n",
            "Epoch: 15 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.049 | Train Acc: 98.18%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RslVdSyE-hg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text, text_lengths = batch.headline\n",
        "            \n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.sarcastic.type_as(predictions))\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.sarcastic.type_as(predictions))\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv5LkXsx-hkF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca904d45-d543-4272-c21c-060a119e2399"
      },
      "source": [
        "# model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.358 | Test Acc: 89.78%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6jfG_ir_m2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Give sarcasm probability of the given sentence based on our model\n",
        "def predict_sarcasm(model, sentence):\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in spacy.load('en').tokenizer(sentence)]\n",
        "    indexed = [HEADLINE.vocab.stoi[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
        "    return prediction.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZAkhyqt_m6g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4712cf6a-6626-4289-c740-c812639ac541"
      },
      "source": [
        "predict_sarcasm(model, \"Cats loving dogs\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.022778959944844246"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    }
  ]
}