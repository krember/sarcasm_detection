{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Sarcasm Detection Local Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krember/sarcasm_detection/blob/master/Sarcasm_Detection_Local_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ca4oUGXGaUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import spacy\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torch import nn, optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO0s0l3f4Q7I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ceb25bb8-f85a-43e9-8ea4-e7f16e858eab"
      },
      "source": [
        "#Let's start from providing Colab access to Google Drive to be able load the file with the data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwFWStIGGaUf",
        "colab_type": "text"
      },
      "source": [
        "Read in the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvQTPs89GaUl",
        "colab_type": "code",
        "outputId": "dca7b50c-0b35-4b02-f947-4f70d6ca9ceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.read_json('/content/drive/My Drive/Deep Learning - AUA/Sarcasm Detection/Sarcasm_Headlines_Dataset.json', lines = True)\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_link</th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        article_link  ... is_sarcastic\n",
              "0  https://www.huffingtonpost.com/entry/versace-b...  ...            0\n",
              "1  https://www.huffingtonpost.com/entry/roseanne-...  ...            0\n",
              "2  https://local.theonion.com/mom-starting-to-fea...  ...            1\n",
              "3  https://politics.theonion.com/boehner-just-wan...  ...            1\n",
              "4  https://www.huffingtonpost.com/entry/jk-rowlin...  ...            0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW0SLLnQ6vLb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ba0b7b5c-82b5-4c4d-a96c-506f8d5b2edf"
      },
      "source": [
        "df = df[['headline','is_sarcastic']]\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  is_sarcastic\n",
              "0  former versace store clerk sues over secret 'b...             0\n",
              "1  the 'roseanne' revival catches up to our thorn...             0\n",
              "2  mom starting to fear son's web series closest ...             1\n",
              "3  boehner just wants wife to listen, not come up...             1\n",
              "4  j.k. rowling wishes snape happy birthday in th...             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZuqyNVT6yL8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "73deb9cd-8eef-4b71-c050-5346df88c2dd"
      },
      "source": [
        "# Check for normalization\n",
        "sns.countplot(df.is_sarcastic)\n",
        "plt.xlabel('Label')\n",
        "plt.title('Sarcasm vs Non-sarcasm')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Sarcasm vs Non-sarcasm')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAZ/UlEQVR4nO3de7hddX3n8ffHRFBH7qSISWyoplq8\nVCEFbDsdKxaCVcNjrQNTS7S0qVN6cWrrbZ4xFsXaaSuKFyqVCFRKRKsltViMXOSpI0gQCwJaIoJJ\nBIkk3ETU4Hf+WL+j23hOOKxk75143q/n2U/W+v5+a63f2ifP+Zx12WunqpAkqY9HjHsAkqRdlyEi\nSerNEJEk9WaISJJ6M0QkSb0ZIpKk3gwRSVJvhoiGKskvJ/l/Se5OsinJZ5L8wrjHtTNJclmSB5LM\nH6g9L8ktYxyWNC2GiIYmyZ7Ax4F3AfsCc4G/AL7TY12zd+zodjrfAv7PuAcxXen4+0OGiIbqZwGq\n6ryqerCqvl1Vn6yqawGSPDHJJUnuTPLNJOcm2Xti4SS3JHltkmuBbyWZPXBkc1eSdUle3vr+epJr\nktzT6m8aWM+jknywbeeuJFclOaC1XZbkLW2d9yX5lyT7tbHc0/oumGznknwiyR9uVfuPJC9uv2RP\nTXJHW891SZ62jffqNOD4JE+cYls/18Z6V5Lrk7xooO2sJO9J8q9J7k1y5VTraf2fn+SG1ndDkj9r\n9X2SfDzJxiSb2/S8geUuS3JKks8A9wM/k+SpSVa3o8xvJHlD63tYks+28d6W5N1JdmttU743bV/e\n297b+9qR6+OSvKON6UtJnrWN91GjVlW+fA3lBewJ3AmcDRwD7LNV+5OAXwN2B+YAlwPvGGi/BfgC\nMB94NPDTwL3A8cAjgf2AZ7a+zwGeTveH0TOAbwDHtrbfB/4FeAwwCzgU2LO1XQasBZ4I7AXcAPwn\n8DxgNnAO8IEp9u8E4DMD8wcDd7X9ORq4GtgbCPBzwIFTrOcy4HeBtwMfbLXnAbe06Ue2Mb4B2A14\nbnsfntzaz2rv82FtzOcCK7fxc7kN+K9teh/gkDa9H/Ab7X3aA/gw8M9bjfNrwFPbdvZo63o18Kg2\nf3jreyhwROu3ALgReFVrm/K9afvyzbb8o4BLgK+293oW8Bbg0nH/3/b1w5dHIhqaqroH+GWggL8H\nNiZZNXEUUFVrq2p1VX2nqjbS/RL9b1ut5rSqWldV3wb+B/Cp6o5svldVd1bVF9q6Lquq66rq+9Ud\n6Zw3sK7v0f2CfFJ1R0RXt7FN+EBVfaWq7gY+AXylqj5VVVvofpFO9Zfvx4BnJvnpNv9bwEer6jtt\nm3sATwFSVTdW1W0P8Zb9JfDCJE/dqn4E8FjgbVX13aq6hO404fGDY6mqz7Uxnws8cxvb+R5wcJI9\nq2pzVX0eoL2f/1RV91fVvcAp/PjP46yqur5t5wXA7VX1t1X1QFXdW1VXtnVdXVVXVNWWqroFeB8/\n+vPY1nvzsbb8A3Tv8QNVdU5VPQh8iKl/HhoDQ0RD1X5BvLyq5gFPAx4PvAMgyQFJVrZTKvcAHwT2\n32oV6wam5wNfmWw7SQ5Pcmk7FXM38MqBdf0DcBGwMsnXk/zfJI8cWPwbA9PfnmT+sVPs273AvwLH\ntdLxdL/Aab/o3w28B7gjyRnprhFNqQXpu4GTt2p6PLCuqr4/ULuV7hrThNsHpu+fGHOSN7TTQvcl\n+bvW/hvA84Fbk3w6ybNb38ckeV+SW9vP43Jg7ySzBtY93Z/Hz7bTYbe3db2V9vOYxnvT6+eh8TBE\nNDJV9SW60xUT1wbeSneU8vSq2hN4Gd3pjR9ZbGB6Hd1pp8n8I7AKmF9VewF/N7GudtTyF1V1MPCL\ndH9Bn7DdO9Q5j+5axrPpTr9c+oOBV51WVYfSneb6WeDPp7G+vwZ+le50zoSvA/PzoxeynwBseKiV\nVdVbq+qx7fXKVruqqpYAPwX8M3B+6/5q4Ml0p6T2BH6l1Qd/Jlv/PH5mik2fDnwJWNjW9YbB9fR8\nb7QTMkQ0NEmekuTVExdn093CejxwReuyB3AfcHeSuTz0L5JzgecleWm6i+z7JZk4bbMHsKmqHkhy\nGN2pr4lx/GqSp7e/qO+hO53y/R9bez8X0l2rORn40MTRQpJfaEdHj6S78+qB6Wyzqu4C/hZ4zUD5\nSrqji9ckeWSS5wAvBFY+3MEm2S3JbyXZq6q+R/d+TIxrD7q/9O9Ksi+w/CFW93HgwCSvSrJ7kj2S\nHD6wrnuA+5I8BfifA2Po9d5o52SIaJjuBQ4HrkzyLbrw+CLdX7zQ3e57CHA33Wmhj25rZVX1NbrT\nMK8GNtFddP/51vwHwMlJ7gXeyA//ugZ4HPARul9qNwKfpjvFtd3a9Y+P0l0I/8eBpj3prgNtpjv1\ndCfdUcZ0vBN4cGAb36ULjWPoLjq/FzihHdn18dvALe000yvpruVAd5rx0W0bVwD/tq2VtNN5v9bG\ndjtwE91RFMCf0QX5vXTvw4cGFt2e90Y7mVT5pVSSpH48EpEk9WaISJJ6M0QkSb0ZIpKk3n7SH2r3\nY/bff/9asGDBuIchSbuUq6+++ptVNWfr+owLkQULFrBmzZpxD0OSdilJbp2s7uksSVJvhogkqTdD\nRJLUmyEiSerNEJEk9WaISJJ6M0QkSb0ZIpKk3gwRSVJvM+4T69vr0D8/Z9xD0E7o6r/eUd+2K+1a\nPBKRJPVmiEiSejNEJEm9GSKSpN4MEUlSb4aIJKk3Q0SS1JshIknqzRCRJPU2tBBJsiLJHUm+OEnb\nq5NUkv3bfJKclmRtkmuTHDLQd2mSm9pr6UD90CTXtWVOS5Jh7YskaXLDPBI5C1i8dTHJfOAo4GsD\n5WOAhe21DDi99d0XWA4cDhwGLE+yT1vmdOD3Bpb7sW1JkoZraCFSVZcDmyZpOhV4DVADtSXAOdW5\nAtg7yYHA0cDqqtpUVZuB1cDi1rZnVV1RVQWcAxw7rH2RJE1upNdEkiwBNlTVf2zVNBdYNzC/vtW2\nVV8/SX2q7S5LsibJmo0bN27HHkiSBo0sRJI8BngD8MZRbXNCVZ1RVYuqatGcOXNGvXlJ+ok1yiOR\nJwIHAf+R5BZgHvD5JI8DNgDzB/rOa7Vt1edNUpckjdDIQqSqrquqn6qqBVW1gO4U1CFVdTuwCjih\n3aV1BHB3Vd0GXAQclWSfdkH9KOCi1nZPkiPaXVknABeMal8kSZ1h3uJ7HvBZ4MlJ1ic5cRvdLwRu\nBtYCfw/8AUBVbQLeDFzVXie3Gq3P+9syXwE+MYz9kCRNbWjfbFhVxz9E+4KB6QJOmqLfCmDFJPU1\nwNO2b5SSpO3hJ9YlSb0ZIpKk3gwRSVJvhogkqTdDRJLUmyEiSerNEJEk9WaISJJ6M0QkSb0ZIpKk\n3gwRSVJvhogkqTdDRJLUmyEiSerNEJEk9WaISJJ6M0QkSb0ZIpKk3gwRSVJvQwuRJCuS3JHkiwO1\nv07ypSTXJvlYkr0H2l6fZG2SLyc5eqC+uNXWJnndQP2gJFe2+oeS7DasfZEkTW6YRyJnAYu3qq0G\nnlZVzwD+E3g9QJKDgeOAp7Zl3ptkVpJZwHuAY4CDgeNbX4C/Ak6tqicBm4ETh7gvkqRJDC1Equpy\nYNNWtU9W1ZY2ewUwr00vAVZW1Xeq6qvAWuCw9lpbVTdX1XeBlcCSJAGeC3ykLX82cOyw9kWSNLlx\nXhP5HeATbXousG6gbX2rTVXfD7hrIJAm6pNKsizJmiRrNm7cuIOGL0kaS4gk+d/AFuDcUWyvqs6o\nqkVVtWjOnDmj2KQkzQizR73BJC8HXgAcWVXVyhuA+QPd5rUaU9TvBPZOMrsdjQz2lySNyEiPRJIs\nBl4DvKiq7h9oWgUcl2T3JAcBC4HPAVcBC9udWLvRXXxf1cLnUuAlbfmlwAWj2g9JUmdoRyJJzgOe\nA+yfZD2wnO5urN2B1d21ca6oqldW1fVJzgduoDvNdVJVPdjW84fARcAsYEVVXd828VpgZZK3ANcA\nZw5rX6RdxddOfvq4h6Cd0BPeeN3Q1j20EKmq4ycpT/mLvqpOAU6ZpH4hcOEk9Zvp7t6SJI2Jn1iX\nJPVmiEiSejNEJEm9GSKSpN4MEUlSb4aIJKk3Q0SS1JshIknqzRCRJPVmiEiSejNEJEm9GSKSpN4M\nEUlSb4aIJKk3Q0SS1JshIknqzRCRJPVmiEiSehtaiCRZkeSOJF8cqO2bZHWSm9q/+7R6kpyWZG2S\na5McMrDM0tb/piRLB+qHJrmuLXNa2pe2S5JGZ5hHImcBi7eqvQ64uKoWAhe3eYBjgIXttQw4HbrQ\nAZYDh9N9n/ryieBpfX5vYLmttyVJGrKhhUhVXQ5s2qq8BDi7TZ8NHDtQP6c6VwB7JzkQOBpYXVWb\nqmozsBpY3Nr2rKorqqqAcwbWJUkakVFfEzmgqm5r07cDB7TpucC6gX7rW21b9fWT1CVJIzS2C+vt\nCKJGsa0ky5KsSbJm48aNo9ikJM0Iow6Rb7RTUbR/72j1DcD8gX7zWm1b9XmT1CdVVWdU1aKqWjRn\nzpzt3glJUmfUIbIKmLjDailwwUD9hHaX1hHA3e2010XAUUn2aRfUjwIuam33JDmi3ZV1wsC6JEkj\nMntYK05yHvAcYP8k6+nusnobcH6SE4FbgZe27hcCzwfWAvcDrwCoqk1J3gxc1fqdXFUTF+v/gO4O\nsEcDn2gvSdIIDS1Equr4KZqOnKRvASdNsZ4VwIpJ6muAp23PGCVJ28dPrEuSejNEJEm9GSKSpN4M\nEUlSb4aIJKk3Q0SS1JshIknqzRCRJPVmiEiSejNEJEm9GSKSpN4MEUlSb4aIJKm3aYVIkounU5Mk\nzSzbfBR8kkcBj6H7TpB9gLSmPfE7zSVpxnuo7xP5feBVwOOBq/lhiNwDvHuI45Ik7QK2GSJV9U7g\nnUn+qKreNaIxSZJ2EdP6ZsOqeleSXwQWDC5TVecMaVySpF3AtEIkyT8ATwS+ADzYygUYIpI0g033\nO9YXAQe370Lfbkn+F/C7dEF0HfAK4EBgJbAf3fWX366q7ybZnS6sDgXuBP57Vd3S1vN64ES6YPvj\nqrpoR4xPkjQ90/2cyBeBx+2IDSaZC/wxsKiqngbMAo4D/go4taqeBGymCwfav5tb/dTWjyQHt+We\nCiwG3ptk1o4YoyRpeqYbIvsDNyS5KMmqidd2bHc28Ogks+luIb4NeC7wkdZ+NnBsm17S5mntRyZJ\nq6+squ9U1VeBtcBh2zEmSdLDNN3TWW/aURusqg1J/gb4GvBt4JN0p6/uqqotrdt6fvg5lLnAurbs\nliR3053ymgtcMbDqwWV+RJJlwDKAJzzhCTtqVyRpxpvu3Vmf3lEbbB9aXAIcBNwFfJjudNTQVNUZ\nwBkAixYt2iHXdSRJ03/syb1J7mmvB5I8mOSentt8HvDVqtpYVd8DPgr8ErB3O70FMA/Y0KY3APPb\nOGYDe9FdYP9BfZJlJEkjMK0Qqao9qmrPqtoTeDTwG8B7e27za8ARSR7Trm0cCdwAXAq8pPVZClzQ\nple1eVr7Je0usVXAcUl2T3IQsBD4XM8xSZJ6eNhP8a3OPwNH99lgVV1Jd4H883S39z6C7lTTa4E/\nTbKW7prHmW2RM4H9Wv1Pgde19VwPnE8XQP8GnFRVDyJJGpnpftjwxQOzj6D73MgDfTdaVcuB5VuV\nb2aSu6uq6gHgN6dYzynAKX3HIUnaPtO9O+uFA9NbgFvoLo5Lkmaw6d6d9YphD0SStOuZ7t1Z85J8\nLMkd7fVPSeYNe3CSpJ3bdC+sf4DubqjHt9e/tJokaQabbojMqaoPVNWW9joLmDPEcUmSdgHTDZE7\nk7wsyaz2ehndB/4kSTPYdEPkd4CXArfTPSzxJcDLhzQmSdIuYrq3+J4MLK2qzQBJ9gX+hi5cJEkz\n1HSPRJ4xESAAVbUJeNZwhiRJ2lVMN0Qe0Z6+C/zgSGS6RzGSpJ9Q0w2CvwU+m+TDbf438XEjkjTj\nTfcT6+ckWUP37YMAL66qG4Y3LEnSrmDap6RaaBgckqQfeNiPgpckaYIhIknqzRCRJPVmiEiSejNE\nJEm9GSKSpN7GEiJJ9k7ykSRfSnJjkmcn2TfJ6iQ3tX/3aX2T5LQka5Ncm+SQgfUsbf1vSrJ0HPsi\nSTPZuI5E3gn8W1U9Bfh54EbgdcDFVbUQuLjNAxwDLGyvZcDp8INHrywHDgcOA5YPPppFkjR8Iw+R\nJHsBvwKcCVBV362qu4AlwNmt29nAsW16CXBOda4A9k5yIHA0sLqqNrWHQ64GFo9wVyRpxhvHkchB\nwEbgA0muSfL+JP8FOKCqbmt9bgcOaNNzgXUDy69vtanqPybJsiRrkqzZuHHjDtwVSZrZxhEis4FD\ngNOr6lnAt/jhqSsAqqqA2lEbrKozqmpRVS2aM8dv9ZWkHWUcIbIeWF9VV7b5j9CFyjfaaSrav3e0\n9g3A/IHl57XaVHVJ0oiMPESq6nZgXZInt9KRdA92XAVM3GG1FLigTa8CTmh3aR0B3N1Oe10EHJVk\nn3ZB/ahWkySNyLi+WOqPgHOT7AbcDLyCLtDOT3IicCvdd7oDXAg8H1gL3N/6UlWbkrwZuKr1O7l9\n46IkaUTGEiJV9QVg0SRNR07St4CTpljPCmDFjh2dJGm6/MS6JKk3Q0SS1JshIknqzRCRJPVmiEiS\nejNEJEm9GSKSpN4MEUlSb4aIJKk3Q0SS1JshIknqzRCRJPVmiEiSejNEJEm9GSKSpN4MEUlSb4aI\nJKk3Q0SS1NvYQiTJrCTXJPl4mz8oyZVJ1ib5UPv+dZLs3ubXtvYFA+t4fat/OcnR49kTSZq5xnkk\n8ifAjQPzfwWcWlVPAjYDJ7b6icDmVj+19SPJwcBxwFOBxcB7k8wa0dglSYwpRJLMA34deH+bD/Bc\n4COty9nAsW16SZuntR/Z+i8BVlbVd6rqq8Ba4LDR7IEkCcZ3JPIO4DXA99v8fsBdVbWlza8H5rbp\nucA6gNZ+d+v/g/oky0iSRmDkIZLkBcAdVXX1CLe5LMmaJGs2btw4qs1K0k+8cRyJ/BLwoiS3ACvp\nTmO9E9g7yezWZx6woU1vAOYDtPa9gDsH65Ms8yOq6oyqWlRVi+bMmbNj90aSZrCRh0hVvb6q5lXV\nAroL45dU1W8BlwIvad2WAhe06VVtntZ+SVVVqx/X7t46CFgIfG5EuyFJAmY/dJeReS2wMslbgGuA\nM1v9TOAfkqwFNtEFD1V1fZLzgRuALcBJVfXg6IctSTPXWEOkqi4DLmvTNzPJ3VVV9QDwm1Msfwpw\nyvBGKEnaFj+xLknqzRCRJPVmiEiSejNEJEm9GSKSpN4MEUlSb4aIJKk3Q0SS1JshIknqzRCRJPVm\niEiSejNEJEm9GSKSpN4MEUlSb4aIJKk3Q0SS1JshIknqzRCRJPVmiEiSeht5iCSZn+TSJDckuT7J\nn7T6vklWJ7mp/btPqyfJaUnWJrk2ySED61ra+t+UZOmo90WSZrpxHIlsAV5dVQcDRwAnJTkYeB1w\ncVUtBC5u8wDHAAvbaxlwOnShAywHDgcOA5ZPBI8kaTRGHiJVdVtVfb5N3wvcCMwFlgBnt25nA8e2\n6SXAOdW5Atg7yYHA0cDqqtpUVZuB1cDiEe6KJM14Y70mkmQB8CzgSuCAqrqtNd0OHNCm5wLrBhZb\n32pT1SfbzrIka5Ks2bhx4w4bvyTNdGMLkSSPBf4JeFVV3TPYVlUF1I7aVlWdUVWLqmrRnDlzdtRq\nJWnGG0uIJHkkXYCcW1UfbeVvtNNUtH/vaPUNwPyBxee12lR1SdKIjOPurABnAjdW1dsHmlYBE3dY\nLQUuGKif0O7SOgK4u532ugg4Ksk+7YL6Ua0mSRqR2WPY5i8Bvw1cl+QLrfYG4G3A+UlOBG4FXtra\nLgSeD6wF7gdeAVBVm5K8Gbiq9Tu5qjaNZhckSTCGEKmqfwcyRfORk/Qv4KQp1rUCWLHjRidJejj8\nxLokqTdDRJLUmyEiSerNEJEk9WaISJJ6M0QkSb0ZIpKk3gwRSVJvhogkqTdDRJLUmyEiSerNEJEk\n9WaISJJ6M0QkSb0ZIpKk3gwRSVJvhogkqTdDRJLUmyEiSeptlw+RJIuTfDnJ2iSvG/d4JGkm2aVD\nJMks4D3AMcDBwPFJDh7vqCRp5tilQwQ4DFhbVTdX1XeBlcCSMY9JkmaM2eMewHaaC6wbmF8PHL51\npyTLgGVt9r4kXx7B2GaC/YFvjnsQO4P8zdJxD0E/zv+fE5ZnR6zlpycr7uohMi1VdQZwxrjH8ZMm\nyZqqWjTucUiT8f/naOzqp7M2APMH5ue1miRpBHb1ELkKWJjkoCS7AccBq8Y8JkmaMXbp01lVtSXJ\nHwIXAbOAFVV1/ZiHNZN4ilA7M/9/jkCqatxjkCTtonb101mSpDEyRCRJvRki6sXHzWhnlWRFkjuS\nfHHcY5kJDBE9bD5uRju5s4DF4x7ETGGIqA8fN6OdVlVdDmwa9zhmCkNEfUz2uJm5YxqLpDEyRCRJ\nvRki6sPHzUgCDBH14+NmJAGGiHqoqi3AxONmbgTO93Ez2lkkOQ/4LPDkJOuTnDjuMf0k87EnkqTe\nPBKRJPVmiEiSejNEJEm9GSKSpN4MEUlSb4aINCRJ7nsYfd+U5M+GtX5pWAwRSVJvhog0QklemOTK\nJNck+VSSAwaafz7JZ5PclOT3Bpb58yRXJbk2yV+MYdjSlAwRabT+HTiiqp5F9wj91wy0PQN4LvBs\n4I1JHp/kKGAh3eP3nwkcmuRXRjxmaUqzxz0AaYaZB3woyYHAbsBXB9ouqKpvA99OcildcPwycBRw\nTevzWLpQuXx0Q5amZohIo/Uu4O1VtSrJc4A3DbRt/QyiAgL8ZVW9bzTDkx4eT2dJo7UXP3xs/tKt\n2pYkeVSS/YDn0D0t+SLgd5I8FiDJ3CQ/NarBSg/FIxFpeB6TZP3A/Nvpjjw+nGQzcAlw0ED7tcCl\nwP7Am6vq68DXk/wc8NkkAPcBLwPuGP7wpYfmU3wlSb15OkuS1JshIknqzRCRJPVmiEiSejNEJEm9\nGSKSpN4MEUlSb/8fRy4u3WNTJBQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riCPbSSxGaU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform dataset to have only headline and sarcastic label\n",
        "# Also split headline text into words\n",
        "HEADLINE = data.Field(tokenize='spacy', include_lengths = True)\n",
        "ISSARCASTIC = data.LabelField()\n",
        "\n",
        "sarcasm_data = data.TabularDataset(\n",
        "    path='/content/drive/My Drive/Deep Learning - AUA/Sarcasm Detection/Sarcasm_Headlines_Dataset.json',\n",
        "    format='json',\n",
        "    fields={\n",
        "        'headline':('headline', HEADLINE),\n",
        "        'is_sarcastic':('sarcastic', ISSARCASTIC)\n",
        "    }\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "290DckQJGaVE",
        "colab_type": "code",
        "outputId": "94ae2078-aae2-4df7-9a43-3450f580ed5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(vars(sarcasm_data[0]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'headline': ['former', 'versace', 'store', 'clerk', 'sues', 'over', 'secret', \"'\", 'black', 'code', \"'\", 'for', 'minority', 'shoppers'], 'sarcastic': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c6fdbd83-0004-444f-8647-6fb748bd8c37",
        "id": "Q5f0ke3zTgsR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Not a good idea to analyse words individually\n",
        "# However, it is obvious that Trump is the largest source of sarcastic headlines )))\n",
        "from collections import Counter\n",
        "c = Counter(\" \".join(df[\"headline\"]).split()).most_common(20)\n",
        "c\n",
        "# Thinking of TF-IDF for future"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('to', 8206),\n",
              " ('of', 5593),\n",
              " ('the', 5177),\n",
              " ('in', 4170),\n",
              " ('for', 3297),\n",
              " ('a', 2961),\n",
              " ('on', 2371),\n",
              " ('and', 1885),\n",
              " ('with', 1797),\n",
              " ('is', 1666),\n",
              " ('new', 1485),\n",
              " ('man', 1229),\n",
              " ('from', 1221),\n",
              " ('at', 1189),\n",
              " ('trump', 1157),\n",
              " ('about', 1051),\n",
              " ('you', 914),\n",
              " ('by', 885),\n",
              " ('this', 882),\n",
              " ('after', 838)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9NQJZm98TeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split to train and test\n",
        "train_data, test_data = sarcasm_data.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoALm8RW9jEW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "138d837d-1575-4abe-be67-242273a68480"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8013"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwMlHch59osd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bulding vocabulary from each sequence of training data\n",
        "HEADLINE.build_vocab(train_data, \n",
        "                 max_size = 50_000, \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "ISSARCASTIC.build_vocab(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIDXYrSr9o9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, test_data), \n",
        "    batch_size = 64,\n",
        "    sort_key = lambda x:len(x.headline),\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYrNkOCF9o7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# recurrent neural network (RNN)\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        super(RNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional,\n",
        "                          dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self, text, text_lengths):\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        return self.fc(hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5FyJlCL9o5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define RNN model ( hyperparameters )\n",
        "EMBEDDING_DIM = 100\n",
        "PAD_IDX = HEADLINE.vocab.stoi[HEADLINE.pad_token]\n",
        "\n",
        "model = RNN(vocab_size = len(HEADLINE.vocab), embedding_dim = EMBEDDING_DIM, hidden_dim = 256,\n",
        "            output_dim = 1, n_layers = 2, bidirectional = True, dropout = 0.5, pad_idx = PAD_IDX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66PdLGLP9o1d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12bb0469-5cd7-412a-bfa3-e046a4695cb5"
      },
      "source": [
        "# Print model parameters summary\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 4,512,157 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ5HDijY9oxm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0319c83f-1521-4832-b747-23490b54a2eb"
      },
      "source": [
        "# Dense vector representation for words\n",
        "pretrained_embeddings = HEADLINE.vocab.vectors\n",
        "\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "UNK_IDX = HEADLINE.vocab.stoi[HEADLINE.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.1897,  0.0500,  0.1908,  ..., -0.3980,  0.4765, -0.1598],\n",
            "        ...,\n",
            "        [ 0.7841, -0.7761,  0.9107,  ...,  0.1644,  0.8103, -0.4275],\n",
            "        [-0.1190,  0.1594,  1.5809,  ..., -0.8869, -1.7106, -0.2449],\n",
            "        [ 0.1803, -0.1979,  0.3402,  ..., -0.2219,  0.3065, -0.2132]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auZp_KT9-Mqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Learning rate optimization\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTcU6ACe-MtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    return correct.sum() / len(correct)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwJ54WLJ-hYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0.0\n",
        "    epoch_acc = 0.0\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        text, text_lengths = batch.headline\n",
        "        \n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "#         print(predictions)\n",
        "        loss = criterion(predictions, batch.sarcastic.type_as(predictions))\n",
        "        acc = binary_accuracy(predictions, batch.sarcastic.type_as(predictions))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgPj0lSp-hd6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "cc037999-3198-4f3a-9bc3-bf046484697e"
      },
      "source": [
        "# Training the model\n",
        "N_EPOCHS = 15\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # Calculated training time of this epoch\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    epoch_mins = int(elapsed_time / 60)\n",
        "    epoch_secs = int(elapsed_time - (epoch_mins * 60))\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.507 | Train Acc: 75.25%\n",
            "Epoch: 02 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.348 | Train Acc: 84.84%\n",
            "Epoch: 03 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.281 | Train Acc: 88.10%\n",
            "Epoch: 04 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.242 | Train Acc: 89.94%\n",
            "Epoch: 05 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.199 | Train Acc: 91.99%\n",
            "Epoch: 06 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.173 | Train Acc: 93.21%\n",
            "Epoch: 07 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.144 | Train Acc: 94.43%\n",
            "Epoch: 08 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.121 | Train Acc: 95.32%\n",
            "Epoch: 09 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.104 | Train Acc: 96.17%\n",
            "Epoch: 10 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.090 | Train Acc: 96.43%\n",
            "Epoch: 11 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.077 | Train Acc: 97.17%\n",
            "Epoch: 12 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.068 | Train Acc: 97.50%\n",
            "Epoch: 13 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.063 | Train Acc: 97.59%\n",
            "Epoch: 14 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.056 | Train Acc: 97.97%\n",
            "Epoch: 15 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.056 | Train Acc: 97.86%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RslVdSyE-hg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text, text_lengths = batch.headline\n",
        "            \n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.sarcastic.type_as(predictions))\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.sarcastic.type_as(predictions))\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv5LkXsx-hkF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73a918f9-602f-4040-9e58-155891bb2cce"
      },
      "source": [
        "# model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.359 | Test Acc: 88.87%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6jfG_ir_m2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Give sarcasm probability of the given sentence based on our model\n",
        "def predict_sarcasm(model, sentence):\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in spacy.load('en').tokenizer(sentence)]\n",
        "    indexed = [HEADLINE.vocab.stoi[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
        "    return prediction.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZAkhyqt_m6g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ee9215c-9a55-4651-a3a1-514126100057"
      },
      "source": [
        "predict_sarcasm(model, \"Cats loving dogs\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.061922043561935425"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}